{"ast":null,"code":"'use strict';\n\nObject.defineProperty(exports, '__esModule', {\n  value: true\n});\n\nvar common = require('./common.js');\n\nvar token = require('./token.js');\n\nvar jump = require('./jump.js');\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\n\nclass Tokeniser {\n  constructor(data) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n\n  done() {\n    return this.pos >= this.data.length;\n  }\n\n  next() {\n    const byt = this.data[this.pos];\n    let token = jump.quick[byt];\n\n    if (token === undefined) {\n      const decoder = jump.jump[byt];\n\n      if (!decoder) {\n        throw new Error(`${common.decodeErrPrefix} no decoder for major type ${byt >>> 5} (byte 0x${byt.toString(16).padStart(2, '0')})`);\n      }\n\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n\n    this.pos += token.encodedLength;\n    return token;\n  }\n\n}\n\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\n\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(`${common.decodeErrPrefix} got unexpected break to lengthed array`);\n    }\n\n    if (value === DONE) {\n      throw new Error(`${common.decodeErrPrefix} found array but not enough entries (got ${i}, expected ${token.value})`);\n    }\n\n    arr[i] = value;\n  }\n\n  return arr;\n}\n\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(`${common.decodeErrPrefix} got unexpected break to lengthed map`);\n    }\n\n    if (key === DONE) {\n      throw new Error(`${common.decodeErrPrefix} found map but not enough entries (got ${i} [no key], expected ${token.value})`);\n    }\n\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${common.decodeErrPrefix} non-string keys not supported (got ${typeof key})`);\n    }\n\n    const value = tokensToObject(tokeniser, options);\n\n    if (value === DONE) {\n      throw new Error(`${common.decodeErrPrefix} found map but not enough entries (got ${i} [no value], expected ${token.value})`);\n    }\n\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n\n  return useMaps ? m : obj;\n}\n\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n\n  const token$1 = tokeniser.next();\n\n  if (token$1.type === token.Type.break) {\n    return BREAK;\n  }\n\n  if (token$1.type.terminal) {\n    return token$1.value;\n  }\n\n  if (token$1.type === token.Type.array) {\n    return tokenToArray(token$1, tokeniser, options);\n  }\n\n  if (token$1.type === token.Type.map) {\n    return tokenToMap(token$1, tokeniser, options);\n  }\n\n  if (token$1.type === token.Type.tag) {\n    if (options.tags && typeof options.tags[token$1.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token$1.value](tagged);\n    }\n\n    throw new Error(`${common.decodeErrPrefix} tag not supported (${token$1.value})`);\n  }\n\n  throw new Error('unsupported');\n}\n\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${common.decodeErrPrefix} data to decode must be a Uint8Array`);\n  }\n\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n\n  if (decoded === DONE) {\n    throw new Error(`${common.decodeErrPrefix} did not find any content to decode`);\n  }\n\n  if (decoded === BREAK) {\n    throw new Error(`${common.decodeErrPrefix} got unexpected break`);\n  }\n\n  if (!tokeniser.done()) {\n    throw new Error(`${common.decodeErrPrefix} too many terminals, data makes no sense`);\n  }\n\n  return decoded;\n}\n\nexports.Tokeniser = Tokeniser;\nexports.decode = decode;\nexports.tokensToObject = tokensToObject;","map":{"version":3,"sources":["/Users/intvirtue/Last-final/node_modules/cborg/cjs/lib/decode.js"],"names":["Object","defineProperty","exports","value","common","require","token","jump","defaultDecodeOptions","strict","allowIndefinite","allowUndefined","allowBigInt","Tokeniser","constructor","data","options","pos","done","length","next","byt","quick","undefined","decoder","Error","decodeErrPrefix","toString","padStart","minor","encodedLength","DONE","Symbol","for","BREAK","tokenToArray","tokeniser","arr","i","tokensToObject","Infinity","tokenToMap","useMaps","obj","m","Map","key","set","token$1","type","Type","break","terminal","array","map","tag","tags","tagged","decode","Uint8Array","assign","tokenizer","decoded"],"mappings":"AAAA;;AAEAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;;AAEA,IAAIC,MAAM,GAAGC,OAAO,CAAC,aAAD,CAApB;;AACA,IAAIC,KAAK,GAAGD,OAAO,CAAC,YAAD,CAAnB;;AACA,IAAIE,IAAI,GAAGF,OAAO,CAAC,WAAD,CAAlB;;AAEA,MAAMG,oBAAoB,GAAG;AAC3BC,EAAAA,MAAM,EAAE,KADmB;AAE3BC,EAAAA,eAAe,EAAE,IAFU;AAG3BC,EAAAA,cAAc,EAAE,IAHW;AAI3BC,EAAAA,WAAW,EAAE;AAJc,CAA7B;;AAMA,MAAMC,SAAN,CAAgB;AACdC,EAAAA,WAAW,CAACC,IAAD,EAAqB;AAAA,QAAdC,OAAc,uEAAJ,EAAI;AAC9B,SAAKC,GAAL,GAAW,CAAX;AACA,SAAKF,IAAL,GAAYA,IAAZ;AACA,SAAKC,OAAL,GAAeA,OAAf;AACD;;AACDE,EAAAA,IAAI,GAAG;AACL,WAAO,KAAKD,GAAL,IAAY,KAAKF,IAAL,CAAUI,MAA7B;AACD;;AACDC,EAAAA,IAAI,GAAG;AACL,UAAMC,GAAG,GAAG,KAAKN,IAAL,CAAU,KAAKE,GAAf,CAAZ;AACA,QAAIX,KAAK,GAAGC,IAAI,CAACe,KAAL,CAAWD,GAAX,CAAZ;;AACA,QAAIf,KAAK,KAAKiB,SAAd,EAAyB;AACvB,YAAMC,OAAO,GAAGjB,IAAI,CAACA,IAAL,CAAUc,GAAV,CAAhB;;AACA,UAAI,CAACG,OAAL,EAAc;AACZ,cAAM,IAAIC,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,8BAA8BL,GAAG,KAAK,CAAG,YAAYA,GAAG,CAACM,QAAJ,CAAa,EAAb,EAAiBC,QAAjB,CAA0B,CAA1B,EAA6B,GAA7B,CAAmC,GAA9H,CAAN;AACD;;AACD,YAAMC,KAAK,GAAGR,GAAG,GAAG,EAApB;AACAf,MAAAA,KAAK,GAAGkB,OAAO,CAAC,KAAKT,IAAN,EAAY,KAAKE,GAAjB,EAAsBY,KAAtB,EAA6B,KAAKb,OAAlC,CAAf;AACD;;AACD,SAAKC,GAAL,IAAYX,KAAK,CAACwB,aAAlB;AACA,WAAOxB,KAAP;AACD;;AAtBa;;AAwBhB,MAAMyB,IAAI,GAAGC,MAAM,CAACC,GAAP,CAAW,MAAX,CAAb;AACA,MAAMC,KAAK,GAAGF,MAAM,CAACC,GAAP,CAAW,OAAX,CAAd;;AACA,SAASE,YAAT,CAAsB7B,KAAtB,EAA6B8B,SAA7B,EAAwCpB,OAAxC,EAAiD;AAC/C,QAAMqB,GAAG,GAAG,EAAZ;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGhC,KAAK,CAACH,KAA1B,EAAiCmC,CAAC,EAAlC,EAAsC;AACpC,UAAMnC,KAAK,GAAGoC,cAAc,CAACH,SAAD,EAAYpB,OAAZ,CAA5B;;AACA,QAAIb,KAAK,KAAK+B,KAAd,EAAqB;AACnB,UAAI5B,KAAK,CAACH,KAAN,KAAgBqC,QAApB,EAA8B;AAC5B;AACD;;AACD,YAAM,IAAIf,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,yCAAtC,CAAN;AACD;;AACD,QAAIvB,KAAK,KAAK4B,IAAd,EAAoB;AAClB,YAAM,IAAIN,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,4CAA4CY,CAAG,cAAchC,KAAK,CAACH,KAAO,GAAhH,CAAN;AACD;;AACDkC,IAAAA,GAAG,CAACC,CAAD,CAAH,GAASnC,KAAT;AACD;;AACD,SAAOkC,GAAP;AACD;;AACD,SAASI,UAAT,CAAoBnC,KAApB,EAA2B8B,SAA3B,EAAsCpB,OAAtC,EAA+C;AAC7C,QAAM0B,OAAO,GAAG1B,OAAO,CAAC0B,OAAR,KAAoB,IAApC;AACA,QAAMC,GAAG,GAAGD,OAAO,GAAGnB,SAAH,GAAe,EAAlC;AACA,QAAMqB,CAAC,GAAGF,OAAO,GAAG,IAAIG,GAAJ,EAAH,GAAetB,SAAhC;;AACA,OAAK,IAAIe,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGhC,KAAK,CAACH,KAA1B,EAAiCmC,CAAC,EAAlC,EAAsC;AACpC,UAAMQ,GAAG,GAAGP,cAAc,CAACH,SAAD,EAAYpB,OAAZ,CAA1B;;AACA,QAAI8B,GAAG,KAAKZ,KAAZ,EAAmB;AACjB,UAAI5B,KAAK,CAACH,KAAN,KAAgBqC,QAApB,EAA8B;AAC5B;AACD;;AACD,YAAM,IAAIf,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,uCAAtC,CAAN;AACD;;AACD,QAAIoB,GAAG,KAAKf,IAAZ,EAAkB;AAChB,YAAM,IAAIN,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,0CAA0CY,CAAG,uBAAuBhC,KAAK,CAACH,KAAO,GAAvH,CAAN;AACD;;AACD,QAAIuC,OAAO,KAAK,IAAZ,IAAoB,OAAOI,GAAP,KAAe,QAAvC,EAAiD;AAC/C,YAAM,IAAIrB,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,uCAAuC,OAAOoB,GAAK,GAAzF,CAAN;AACD;;AACD,UAAM3C,KAAK,GAAGoC,cAAc,CAACH,SAAD,EAAYpB,OAAZ,CAA5B;;AACA,QAAIb,KAAK,KAAK4B,IAAd,EAAoB;AAClB,YAAM,IAAIN,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,0CAA0CY,CAAG,yBAAyBhC,KAAK,CAACH,KAAO,GAAzH,CAAN;AACD;;AACD,QAAIuC,OAAJ,EAAa;AACXE,MAAAA,CAAC,CAACG,GAAF,CAAMD,GAAN,EAAW3C,KAAX;AACD,KAFD,MAEO;AACLwC,MAAAA,GAAG,CAACG,GAAD,CAAH,GAAW3C,KAAX;AACD;AACF;;AACD,SAAOuC,OAAO,GAAGE,CAAH,GAAOD,GAArB;AACD;;AACD,SAASJ,cAAT,CAAwBH,SAAxB,EAAmCpB,OAAnC,EAA4C;AAC1C,MAAIoB,SAAS,CAAClB,IAAV,EAAJ,EAAsB;AACpB,WAAOa,IAAP;AACD;;AACD,QAAMiB,OAAO,GAAGZ,SAAS,CAAChB,IAAV,EAAhB;;AACA,MAAI4B,OAAO,CAACC,IAAR,KAAiB3C,KAAK,CAAC4C,IAAN,CAAWC,KAAhC,EAAuC;AACrC,WAAOjB,KAAP;AACD;;AACD,MAAIc,OAAO,CAACC,IAAR,CAAaG,QAAjB,EAA2B;AACzB,WAAOJ,OAAO,CAAC7C,KAAf;AACD;;AACD,MAAI6C,OAAO,CAACC,IAAR,KAAiB3C,KAAK,CAAC4C,IAAN,CAAWG,KAAhC,EAAuC;AACrC,WAAOlB,YAAY,CAACa,OAAD,EAAUZ,SAAV,EAAqBpB,OAArB,CAAnB;AACD;;AACD,MAAIgC,OAAO,CAACC,IAAR,KAAiB3C,KAAK,CAAC4C,IAAN,CAAWI,GAAhC,EAAqC;AACnC,WAAOb,UAAU,CAACO,OAAD,EAAUZ,SAAV,EAAqBpB,OAArB,CAAjB;AACD;;AACD,MAAIgC,OAAO,CAACC,IAAR,KAAiB3C,KAAK,CAAC4C,IAAN,CAAWK,GAAhC,EAAqC;AACnC,QAAIvC,OAAO,CAACwC,IAAR,IAAgB,OAAOxC,OAAO,CAACwC,IAAR,CAAaR,OAAO,CAAC7C,KAArB,CAAP,KAAuC,UAA3D,EAAuE;AACrE,YAAMsD,MAAM,GAAGlB,cAAc,CAACH,SAAD,EAAYpB,OAAZ,CAA7B;AACA,aAAOA,OAAO,CAACwC,IAAR,CAAaR,OAAO,CAAC7C,KAArB,EAA4BsD,MAA5B,CAAP;AACD;;AACD,UAAM,IAAIhC,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,uBAAuBsB,OAAO,CAAC7C,KAAO,GAA5E,CAAN;AACD;;AACD,QAAM,IAAIsB,KAAJ,CAAU,aAAV,CAAN;AACD;;AACD,SAASiC,MAAT,CAAgB3C,IAAhB,EAAsBC,OAAtB,EAA+B;AAC7B,MAAI,EAAED,IAAI,YAAY4C,UAAlB,CAAJ,EAAmC;AACjC,UAAM,IAAIlC,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,sCAAtC,CAAN;AACD;;AACDV,EAAAA,OAAO,GAAGhB,MAAM,CAAC4D,MAAP,CAAc,EAAd,EAAkBpD,oBAAlB,EAAwCQ,OAAxC,CAAV;AACA,QAAMoB,SAAS,GAAGpB,OAAO,CAAC6C,SAAR,IAAqB,IAAIhD,SAAJ,CAAcE,IAAd,EAAoBC,OAApB,CAAvC;AACA,QAAM8C,OAAO,GAAGvB,cAAc,CAACH,SAAD,EAAYpB,OAAZ,CAA9B;;AACA,MAAI8C,OAAO,KAAK/B,IAAhB,EAAsB;AACpB,UAAM,IAAIN,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,qCAAtC,CAAN;AACD;;AACD,MAAIoC,OAAO,KAAK5B,KAAhB,EAAuB;AACrB,UAAM,IAAIT,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,uBAAtC,CAAN;AACD;;AACD,MAAI,CAACU,SAAS,CAAClB,IAAV,EAAL,EAAuB;AACrB,UAAM,IAAIO,KAAJ,CAAW,GAAGrB,MAAM,CAACsB,eAAiB,0CAAtC,CAAN;AACD;;AACD,SAAOoC,OAAP;AACD;;AAED5D,OAAO,CAACW,SAAR,GAAoBA,SAApB;AACAX,OAAO,CAACwD,MAAR,GAAiBA,MAAjB;AACAxD,OAAO,CAACqC,cAAR,GAAyBA,cAAzB","sourcesContent":["'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar common = require('./common.js');\nvar token = require('./token.js');\nvar jump = require('./jump.js');\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = jump.quick[byt];\n    if (token === undefined) {\n      const decoder = jump.jump[byt];\n      if (!decoder) {\n        throw new Error(`${ common.decodeErrPrefix } no decoder for major type ${ byt >>> 5 } (byte 0x${ byt.toString(16).padStart(2, '0') })`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ common.decodeErrPrefix } got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found array but not enough entries (got ${ i }, expected ${ token.value })`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ common.decodeErrPrefix } got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found map but not enough entries (got ${ i } [no key], expected ${ token.value })`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${ common.decodeErrPrefix } non-string keys not supported (got ${ typeof key })`);\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found map but not enough entries (got ${ i } [no value], expected ${ token.value })`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token$1 = tokeniser.next();\n  if (token$1.type === token.Type.break) {\n    return BREAK;\n  }\n  if (token$1.type.terminal) {\n    return token$1.value;\n  }\n  if (token$1.type === token.Type.array) {\n    return tokenToArray(token$1, tokeniser, options);\n  }\n  if (token$1.type === token.Type.map) {\n    return tokenToMap(token$1, tokeniser, options);\n  }\n  if (token$1.type === token.Type.tag) {\n    if (options.tags && typeof options.tags[token$1.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token$1.value](tagged);\n    }\n    throw new Error(`${ common.decodeErrPrefix } tag not supported (${ token$1.value })`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${ common.decodeErrPrefix } data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${ common.decodeErrPrefix } did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${ common.decodeErrPrefix } got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${ common.decodeErrPrefix } too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\n\nexports.Tokeniser = Tokeniser;\nexports.decode = decode;\nexports.tokensToObject = tokensToObject;\n"]},"metadata":{},"sourceType":"script"}